{
  "version": "https://jsonfeed.org/version/1.1",
  "title": "ada's blog",
  "description": "just a collection of thoughts~",
  "home_page_url": "https://chronovore.dev/posts",
  "feed_url": "https://chronovore.dev/posts/feed.json",
  "authors": [
    {
      "name": "Ada"
    }
  ],
  "generator": "pumpkin",
  "language": "en",
  "items": [
    {
      "title": "some notes about gaming on linux",
      "url": "https://chronovore.dev/posts/2024-06-22-0436A-linux-gaming-notes.html",
      "id": "tag:chronovore.dev,posts:2024-06-22-0436A-linux-gaming-notes",
      "summary": "this is mostly so i don't forget",
      "date_published": "2024-06-22T03:36:00+00:00",
      "date_modified": "2024-09-22T07:16:00+00:00",
      "content_text": "I recently migrated to using Linux full time.\nYou need to not look far to find an ocean of reasons why Windows has been a bit miserable.\n\nThis post mainly serves as a logbook for fixes and workarounds for making games (and some applications) work on Linux.\n\n[TOC]\n\n## EAC \"Failed to Intialize Dependencies\" error\n\nThis is likely due to a `SDL_VIDEODRIVER` and/or `SDL_VIDEO_DRIVER` environment variable being present.\n\nTry using the following launch arguments:\n\n`env --unset=SDL_VIDEODRIVER --unset=SDL_VIDEO_DRIVER %command%`\n\nAlternatively, set the variable to an empty string in whatever launch manager you're using (Heroic, Lutris).\n\n## Enabling DX12 Ray Tracing\n\nIf you have a ray tracing capable GPU (RTX 2000 or newer, RX 6800 or newer)\nyou might be able to tell Mesa and VKD3D that ray-tracing can be enabled by using the following launch arguments:\n\n`env RADV_PERFTEST=rt VKD3D_CONFIG=dxr VKD3D_FEATURE_LEVEL=12_2 %command%`\n\nIf you have an older GPU you can try:\n\n`env RADV_PERFTEST=emulate_rt VKD3D_CONFIG=dxr VKD3D_FEATURE_LEVEL=12_2 %command%`\n\nThis assumes you have a relatively recent VKD3D and Mesa installation,\nand the game has to support ray tracing in any capacity (i.e. World of Warcraft, Ratchet and Clank: Rift Apart)\n\n## Games not capturing mouse cursor\n\nSome games don't play nice with mouse capture, an easy way to solve this is by changing the launch arguments to:\n\n`gamescope --force-grab-cursor -f %command%`\n\nYou may swap -f with -b for borderless windowed instead of fullscreen.\n\n## Gamescope exiting early due to short-lived launcher processes\n\nSome games launch via third party launchers that cause gamescope to exit before the wine device.\n\nThis may be solved by forcing the SDL backend.\n\n`gamescope --backend sdl %command%`\n\n## Gamescope resolution being fixed to the first window size under SDL\n\nGamescope under SDL has a hard time adjusting to resolution changes (i.e. if you're using it for launcher processes.), to solve this you must force the window to be fullscreen.\n\n`gamescope -w YOUR_RESOLUTION_HERE -h YOUR_RESOLUTION_HERE -r YOUR_REFRESH_RATE_HERE --backend sdl --force-windows-fullscreen -f %command%`\n\n(Special thanks to [Hollyrious](https://twitch.tv/hollyrious) for helping me diagnose this!)\n\n## Windows-only Third-Party Mod Tooling\n\nYou can add the mod tools as a non-steam game, given it has a GUI.\n\nWhen you do, force it to use **the same compatability tools as the game** and set the launch arguments to:\n\n`env STEAM_COMPAT_DATA_PATH=\"~/.steam/root/steamapps/compatdata/489830\" %command%`\n\nYou may need to install more dependencies like .NET 4.8/6.0, etc via protontricks, select the game *not* the non-steam app when installing.\n\nChange `~/.steam/root/steamapps` to the SteamLibrary steamapps folder if installed in a steam library folder.\n\nChange 489830 to match the steam id of the mod tool the game is for, 489830 is Skyrim SE/AE.\nIt is the number after `/app/` in the Steam store link, alternatively look it up on SteamDB.\n\n## Game-Specific Fixes\n\n### Dauntless\n\nIf you randomly crash, it might be because of stack smashing due to a race condition.\n\nI have managed to reduce the frequency of crashes by limiting how many resources the game can use.\n\n`env DXVK_CONFIG=\"dxvk.numCompilerThreads=1\" WINE_CPU_TOPOLOGY=\"4:0,2,4,6\" %command%`\n\nIf there is too much lag, you might want to redefine the CPU topology, i.e. `WINE_CPU_TOPOLOGY=\"8:0,1,2,3,4,5,6,7\"`\n\n## Changelog\n\n*Update: 2024-09-22 - Added gamescope-related workarounds.*"
    },
    {
      "title": "of records and spans",
      "url": "https://chronovore.dev/posts/2024-03-01-0720P-of-records-and-spans.html",
      "id": "tag:chronovore.dev,posts:2024-03-01-0720P-of-records-and-spans",
      "summary": "this is just me rambling about a csharp feature",
      "date_published": "2024-03-01T19:20:00+00:00",
      "date_modified": "2024-03-01T19:20:00+00:00",
      "content_text": "This post is mostly just me speaking fondly of Spans and Records\nwith no real technical information besides how cool they are and their use cases.\n\nThis is not a guide, or tutorial, or a technical writeup.\nJust good vibes about new language features.\n\nBeware! It does get a bit rambly at times.\n\nAnyway, let's go back a few years, to the year 2015...\n\n## Spans\n\n.NET 2015 just released, bringing along with it better control over the\n.NET Garbage Collector and a little footnote that reads:\n\n> .NET Core packages such as the immutable collections, SIMD APIs, and\n> networking APIs such as those found in the System.Net.Http namespace\n> are now available as open-source packages on GitHub.\n\n.NET was moving to open source.\n\nFast forward another 3 years, it's now 2018.\n\nAn update to .NET Core is released, .NET Core 2.1, bringing with it four new\ntypes that represent a whole new programming paradigm. Span, and Memory.\n\nSpan is unique in that it's a **reference struct.** Preventing it from moving\nout of the stack.\n\n### Wait, C# has a stack?\n\nYes! C# has several tiers of memory management, the stack exists in the smallest\narea. This space always exist, and it's where variables end up.\nEvery time you do a `new AwesomeClass()` or `new string[]`, it makes this in\nthe heap and just stores a bit of info on where this is in the heap in the stack\n\n### So how does this relate to Span?\n\nWhen you create a span via `new Span<T>()` or read a memory segment via `(Span<T>) SomeArray`,\nthis value entirely lives in the stack and only in the stack. Meaning you cannot\nstore it in the heap.\n\n### Isn't this a massive issue with OOP designs?\n\nNot if you consider what Span is used for. Span allows you to quickly wrap and\nmanipulate structures and arrays without actually copying memory repeatedly.\n\nLet's say I'm reading a small file, and I need to read the opening for a blog\nsummary. This line is expected to be about... 40 characters long. What I can do\nis read this line without actually allocating any heap memory using `stackalloc`\nTurns out this is a massive speed improvement. Who guessed not allocating memory\nis faster?\n\nMemory is the functional equivalent of Span, except that it lives in the heap.\nThis means it has the luxury of granting a Span (without allocating more\nmemory!) and having access to all of the features, such as _Slicing._\n\n### Slicing?\n\nSlicing is taking a portion of an array, in such that you can manipulate and\nmove it around better. With memory and spans, it just makes a new struct with\nthe same data with some info to only work on that specific range.No data gets\ncopied, whereas making a slice in Arrays requires building (and copying!) a\nwhole second array.\n\nUsing Span (when allocated using `stackalloc`) and Memory buffers (if you need\nto allocate in to the heap), you can easily avoid repeatedly allocating and\nduplicating data which in turn results in major speed gains.\n\n### But what about Native Interopability?\n\nYou know how, if you want to pass an array into a native library method,\nyou would have to do something like:\n\n```cs\n[DllImport] void NativeCall(byte* buffer, int size);\n\nbyte[] myArray = new byte[100];\nunsafe {\n    fixed(byte* pointer = &myArray[0]) {\n        NativeCall(pointer, myArray.Length);\n    }\n}\n```\n\nWell, using Memory this is not only safer, but also a way nicer API.\n\n```cs\nMemory<byte> myArray = new byte[100];\nusing var memoryHandle = myArray.Pin();\nNativeCall(memoryHandle.Pointer, myArray.Length);\n```\n\nPretty cool huh?\n\n## Records\n\nWe're still in 2018, so let's move forwards a bit to 2020.\n.NET 5 just released, marking the start of a new era.\nDotnet is finally, fully and properly cross platform.\nWith it comes a new kind of structure, `record` and `record struct`\n\n### How is this different from `class` and `struct`, aren't they just the same?\n\nFunctionally, there are a few different expectations with records that are\nquite important. _Records prefer to be immutable._\nIt also introduced a few concepts such as\n**primary constructors and init-only properties**\n\nLet's imagine I have a class called `MeowAction` that is something like:\n\n```cs\npublic class MeowAction {\n    public float Volume { get; set; }\n    public Subject MeowedAt { get; set; }\n    public DateTimeOffset MeowedAtTime { get; set; } = DateTimeOffset.UtcNow;\n   \n    public MeowAction(float vol, Subject subject) {\n        Volume = vol;\n        MeowedAt = subject;\n    }\n}\n\n// later...\n\nnew MeowAction(Volume.Loud, RandomStranger());\n```\n\nSimple meow-keeping class for a meow auditing system. However, as a data holding class\nit's still doing some amount of predictable copying (which can be an issue!)\n\nWhat if I told you this is the exact use case for Records?\n\nLet's reimplement it as a record:\n\n```cs\npublic record MeowAction(float Volume, Subject MeowedAt) {\n    public DateTimeOffset MeowedAtTime { get; init; } = DateTimeOffset.UtcNow;\n}\n```\n\nWay smaller, right?\n\n### Wait, init? What happened to set?\n\nWith primary constructors in records, the default behavior is to mark properties as init-only.\nAs such, if you want to have the parameters as a normal get, set pair you would have to\nsomething like:\n\n```cs\npublic record MeowAction(float Volume, Subject MeowedAt) {\n    public float Volume { get; set; } = Volume;\n    public DateTimeOffset MeowedAtTime { get; init; } = DateTimeOffset.UtcNow;\n}\n```\n\n### Could this not be integrated into a class?\n\nAs it turns out, it has.\nThere's nothing stopping you from using `class` instead of `record`\n\nSo why all this fanfare then? Because that's the beauty of records.\nIt shows that C# is willing to adopt new designs, such as...\n\n### It has deconstructors for the primary constructor arguments\n\n```cs\nvar action = new MeowAction(Volume.Loud, RandomStranger());\nvar (volume, subject) = action;\n```\n\n### It generates ToString\n\n```cs\nvar action = new MeowAction(Volume.Loud, RandomStranger());\naction.ToString();\n// MeowAction { Volume = 85.0, MeowedAt = Person { Name = \"Ada\" }, MeowedAtTime = 2165-06-02 }\n```\n\n### It generates GetHashCode\n\n```cs\nvar action = new MeowAction(Volume.Loud, RandomStranger());\naction.GetHashCode(); // HashCode.Combine(Volume, MeowedAt, MeowedAtTime);\n```\n\n### It clones\n\n```cs\nvar action = new MeowAction(Volume.Loud, RandomStranger());\nvar mutated = action with { Volume = Volume.VeryLoud };\n```\n\n### Cloning?!\n\nRemember when I mentioned that Records prefer to be immutable?\nThis is how you get around that.\n\nAny property marked with `set` or `init` can be mutated using curly braces like this.\nThe `with` keyword just happens to copy every value that isn't specified.\n\n## Conclusion\n\nThis was a quite long but non-exhaustive fanfare for Span, Memory, and Records.\nIt's an exciting time to develop in C#, the language progressively is introducing\nnew featuers (such as nullability checks!) that improve code quality, speed and\noverall encourage a more reliable way of programming.\n\nI encourage you to consider weaving stackalloc, Span, Memory, Records,\nand Struct Records into your projects targeting .NET 7 and newer.\n\nHint: A good use case of the `record` keyword are options or settings objects.\n\n### Secret afterword\n\nDid you know that you can have a `readonly record struct` which enforces complete immutability?\n\n### Special Thanks\n\nThanks to [scarletquasar](https://github.com/scarletquasar) for some corrections."
    },
    {
      "title": "json-ld is misused",
      "url": "https://chronovore.dev/posts/2023-07-29-0925A-activity-jsonld-rot.html",
      "id": "tag:chronovore.dev,posts:2023-07-29-0925A-activity-jsonld-rot",
      "summary": "it's not just fancy json.",
      "date_published": "2023-07-28T08:25:00+00:00",
      "date_modified": "2023-07-28T08:25:00+00:00",
      "content_text": "# as always, context is important\n\nActivityStreams is a subset of JSON-LD, specifically the compacted form.\n\n> This specification describes a JSON-based RFC7159 serialization syntax for the Activity Vocabulary that conforms to a subset of JSON-LD syntax constraints but does not require JSON-LD processing. While other serialization forms are possible, such alternatives are not discussed by this document[^assyntax].\n\n> The serialized JSON form of an Activity Streams 2.0 document MUST be consistent with what would be produced by the standard JSON-LD 1.0 Processing Algorithms and JSON-LD-API Compaction Algorithm using, at least, the normative JSON-LD @context definition provided here[^asjsonld].\n\n[^assyntax]: [https://www.w3.org/TR/activitystreams-core/#syntaxconventions](https://www.w3.org/TR/activitystreams-core/#syntaxconventions)\n[^asjsonld]: [https://www.w3.org/TR/activitystreams-core/#jsonld](https://www.w3.org/TR/activitystreams-core/#jsonld0)\n\nThis essentially looks like fancy JSON with a schema attached to it.\nBut it's not... That `@context` is important, and **not** set in stone.\n\n> For extensions, JSON-LD is used as the primary mechanism for defining and disambiguating extensions. Implementations that wish to fully support extensions SHOULD use JSON-LD mechanisms. \n\n> It is important to note that the JSON-LD Processing Algorithms, as currently defined, will silently ignore any property not defined in a JSON-LD @context. Implementations that publish Activity Streams 2.0 documents containing extension properties SHOULD provide a @context definition for all extensions[^asextensibility]. \n\n[^asextensibility]:[https://www.w3.org/TR/activitystreams-core/#extensibility](https://www.w3.org/TR/activitystreams-core/#extensibility)\n\nWhile Activity vocabulary is set in stone and should not and will not ever change,\nExtensions are not.\n\nWhen sending an ActivityStreams message, you cannot rename, override or replace ActivityStreams predicates but this does not apply to extensions.\n\nGiven the following example:\n\n```json\n{\n  \"@context\": [\n    \"https://www.w3.org/ns/activitystreams\",\n    {\n        \"foo\": \"http://example.org/foo\"\n    }\n  ],\n  \"@id\": \"https://example.org/example/note\",\n  \"type\": \"Note\",\n  \"content\": \"This is a simple note\",\n  \"foo\": 123\n}\n```\n\nThis is still a valid ActivityStreams message, but **you should avoid accessing `\"foo\"` directly.**\n\nWhy? Overlap and disambiguation.\n\n```json\n{\n  \"@context\": [\n    \"https://www.w3.org/ns/activitystreams\",\n    {\n        \"foo\": \"http://example.org/foo\",\n        \"other_foo\": \"http://another.example.org/foo\"\n    }\n  ],\n  \"@id\": \"https://example.org/example/note\",\n  \"type\": \"Note\",\n  \"content\": \"This is a simple note\",\n  \"foo\": 123,\n  \"other_foo\": 456\n}\n```\n\nBoth `\"foo\"` and `\"other_foo\"` are `foo` terms. \nThey can swap, or even be a different term entierly. It's implementation-defined.\nThis would still be a valid JSON-LD object and a valid Activity Object.\n\nThen, there's also the use of IRIs.\n\n```json\n{   \n  \"@context\": [\n    \"https://www.w3.org/ns/activitystreams\",\n    {\n        \"ex\": \"http://example.org/\",\n        \"foo\": \"ex:foo\",\n        \"ex2\": \"http://another.example.org/\"\n    }\n  ],\n  \"@id\": \"https://example.org/example/note\",\n  \"type\": \"Note\",\n  \"content\": \"This is a simple note\",\n  \"foo\": 123,\n  \"ex2:foo\": 456\n}\n```\n\nThis one is more set-in-stone, however you should still verify that the namespace is actually what you expect. \nHowever now everyone is forced to use \"ex2:foo\" if we were to include this extension (much like we're currently forced to use the short IRI `\"vcard:location\"`)\n\nJSON-LD algorithms would transform all three objects, essentially into:\n\n```json\n{\n  \"@id\": \"https://example.org/example/note\",\n  \"https://www.w3.org/ns/activitystreams/type\": \"Note\",\n  \"https://www.w3.org/ns/activitystreams/content\": \"This is a simple note\",\n  \"http://example.org/foo\": 123,\n  \"http://another.example.org/foo\": 456\n}\n```\n\nand\n\n```json\n{\n  \"@id\": \"https://example.org/example/note\",\n  \"as:type\": \"Note\",\n  \"as:content\": \"This is a simple note\",\n  \"ex:foo\": 123,\n  \"ex2:foo\": 456\n}\n```\n\nYou would then just access it via either it's shortened IRI, or it's full URI-- disambiguating the result.\nThis is very important because as ActivityPub is getting more popular, and more third-party extensions are introduced by Litepub, Misskey, and others.\n\nI found this out when I was looking into adding `schema:license` and `schema:description` into ActivityStreams' `Image` type. \nTo provide a means to define a copyright SPDX and/or author citation, while also allowing for descriptive text[^ap-descriptive-text].\nAs it stands right now, i'm using `schema:license` and `schema:description` directly into the object;\nnow knowing that every implementation will have to blindly check that short IRI.\n\n[^ap-descriptive-text]: ActivityPub nor ActivityStreams defines how descriptive text is supposed to be federated. Right now most implementations store in the `\"name\"` field of the Image which I find a bit silly especially since new implementations might be unaware of this quirk and potentially use a giant blob of text as the filename if they make the same assumption I did.\n\nThe only social-network-style ActivityPub implementation that I've found that implements proper JSON-LD parsing is GoToSocial,\nwhich very effectively utilizes Go's struct tags to map JSON-LD URIs to struct fields.\n\nI do understand that processing JSON-LD at all is way more computationally heavy than JSON by itself, \nbut if you're going to introduce JSON-LD extension contexts **please** create a json-ld spec file[^its-just-xml].\n\nYou can federate anything over ActivityStreams, even new Activity types if you wanted-- as long as you properly define them.\nSupport for them in other platforms might not ever exist, though.\n\n[^its-just-xml]: Compacted JSON-LD is essentially just JSON with XMLNS DTD features."
    },
    {
      "title": "compression algorithms",
      "url": "https://chronovore.dev/posts/2023-01-25-1234P-compression-deepdive.html",
      "id": "tag:chronovore.dev,posts:2023-01-25-1234P-compression-deepdive",
      "summary": "a deep dive into compression algorithms and how to notice them in hex",
      "date_published": "2023-01-25T14:42:00+00:00",
      "date_modified": "2024-09-09T15:01:00+00:00",
      "content_text": "# Compression Algorithms\n\nOne of the things that my programmer friends often ask me about is how I can tell what kind of compression algorithm is used by a file.\nThis is an interesting question, and I hope that this post will help you understand how I notice compression algorithms in hex.\n\nI will not be going over the fundamentals of compression algorithms or go into detail about how they work.\n\nThe forum posts[^eyes] and reference docs that have taught me how to do this are referenced where appropriate.\n\nI will explain some of the structure of how the compression algorithms are set up because I believe that understanding _what_ these values mean,\nit will help you understand _why_ they are there and how to notice them when the configuration values are anything but the defaults.\n\nAll magic values are written as byte sequences (i.e. big endian)\n\n[^eyes]: [https://zenhax.com/viewtopic.php?t=27](https://web.archive.org/web/20230109220055/https://zenhax.com/viewtopic.php?t=27) (archived)\n\n[TOC]\n\n## The Basics\n\nThe first thing you need to know is that compression algorithms are not magic.\nIn many cases compression algorithms have a sanity check (a \"magic\" number) that is used to verify and set up the decompressor.\nIn other cases parts of the data can be seen in the compressed data.\n\n## The Dreaded Lempel-Ziv Algorithm (Lz*)\n\nThe Lempel-Ziv algorithm is a compression algorithm that is used in many compression formats.\nIt comes in a lot of flavors and figuring out which one is used can be difficult.\n\nTo figure out if a file might be compressed with an Lz algorithm, you should look for the following:\n\n- The first byte is almost always `0F`, `1F`, `F0`, or `FF`\n- The following bytes are seemingly uncompressed data.\n- The first byte repeats itself frequently in the data, especially at the start of the file.\n\nThis is because LZ algorithms use a dictionary to store data that has been seen before,\nand the first byte (the \"block\") is used to determine the length of the data to be copied from the dictionary.\n\nI strongly suggest using comscan[^comscan] with quickbms[^bms] to test what compression algorithm is used by a file when you encounter this and LZ4 (see below) does not work.\n\n[^comscan]: [https://zenhax.com/viewtopic.php?t=23](https://web.archive.org/web/20221125023314/https://zenhax.com/viewtopic.php?t=23) (archived)\n\n[^bms]: [https://aluigi.altervista.org/quickbms.htm](https://aluigi.altervista.org/quickbms.htm)\n\n### LZ4\n\nLZ4[^lz4] is a common compression algorithm used especially in video games during the 2010s.\n\nLZ4's block has the following format:\n\n```c\nstruct lz4_block {\n    uint8_t encode_count : 4;\n    uint8_t literal_count : 4;\n}\n```\n\nThe `encode_count` is the number of bytes to copy from the decompressed stream, and the `literal_count` is the number of bytes to copy from the compressed data.\nThere is also a special case where either byte is `0F`, which means that the next bytes are added to the count (until the byte is no longer `FF`).\nThe minimal number of literals read is 4.\n\n[^lz4]: [https://github.com/lz4/lz4/](https://github.com/lz4/lz4/)\n\n\n### LZMA, and LZMA2\n\nLZMA[^7z] has no hard defined header[^lzma], though it will often start with `5D` or `2C` followed by a 32-bit integer that is the size of the inline dictionary data (usually zero.)\n\nLZMA2 likewise has no header, though it will often start with `18` followed by compressed data. Note that this byte is optional.\n\nI have not yet seen a raw LZMA stream in the wild beyond 7z files, likely due to it's large overhead.\n\n[^7z]: [https://7-zip.org/sdk.html](https://7-zip.org/sdk.html)\n[^lzma]: [https://github.com/jljusten/LZMA-SDK/blob/20d713a28e5aee284f5671c7cf41ffa52db0215e/DOC/lzma-specification.txt](https://github.com/jljusten/LZMA-SDK/blob/20d713a28e5aee284f5671c7cf41ffa52db0215e/DOC/lzma-specification.txt)\n\n\n## DEFLATE, Zlib, and GZip\n\nDEFLATE[^zlib] is a compression algorithm that is used in many files, and you will most likely have already seen it if you do any amount of file analysis.\n\nZLib uses a DEFLATE block with a header, and ADLER32 as it's checksum algorithm.\n\n[^zlib]: [https://github.com/madler/zlib](https://github.com/madler/zlib)\n\n### ZLib\n\nZLib[^rfc1950] preprends a 2 byte header to the compressed block (usually deflate). This usually is `78 9C` or `78 DA`\n\nThe first byte is the compression method, and the second byte has some flags. The compression method is usually `8`, which is DEFLATE.\n\n```c\nstruct zlib_header {\n    uint8_t compression_method : 4;\n    uint8_t compression_info : 4;\n    uint8_t checksum : 5;\n    uint8_t dict : 1;\n    uint8_t level : 2;\n}\n```\n\nThe `compression_info` is the log base 2 of the window size (the size of the dictionary used by the compressor), and the `checksum` a the checksum of the header.\nThe `dict` flag is set if a dictionary is used, and the `level` is the compression level used by the compressor.\n\nKnowing this, zlib header will always start with `78` if the compression method is DEFLATE.\n\n[^rfc1950]: [https://tools.ietf.org/html/rfc1950](https://tools.ietf.org/html/rfc1950)\n\n### DEFLATE\n\nA \"raw\" DEFLATE[^rfc1951] stream is not very common, but it is still used in some places (especially in files produced by C# projects).\n\nIt usually starts with `C#` or `E#` but it's a bit more complicated than that.\n\nThe DEFLATE block has the following format:\n\n```c\nstruct deflate_block {\n    uint8_t final : 1;\n    uint8_t type : 2;\n}\n```\n\nThe `final` flag is set if this is the last block in the stream, and the `type` is the type of block.\n\n[^rfc1951]: [https://tools.ietf.org/html/rfc1951](https://tools.ietf.org/html/rfc1951)\n\n### GZip\n\nGZip[^rfc1952] is a ZLib stream with a well formed header.\n\nGZip will always start with a magic number (`1F 8B`) as well as a compression method (`8` for DEFLATE).\n\nThe header has the following format:\n\n```c\nstruct gzip_header {\n    uint16_t magic;\n    uint8_t compression_method;\n    uint8_t flags;\n    uint32_t timestamp;\n    uint8_t xtra_flags;\n    uint8_t os;\n}\n```\n\n[^rfc1952]: [https://tools.ietf.org/html/rfc1952](https://tools.ietf.org/html/rfc1952)\n\n## ZStandard\n\nZStandard[^zstd] (zstd) is a relatively new compression algorithm that is starting to be used in many places due to it's ability to have very high compression ratios with specialized dictionaries.\n\nFortunately, ZStandard has a magic number that is used to identify the file, this usually is `## B5 2F FD` with the unknown byte being the specific version.\n\nThe ZStandard header has the following format[^zstddoc]:\n\n```c\nstruct zstd_header {\n    uint32_t magic;\n    uint8_t content_size_flag : 2;\n    uint8_t single_segment_flag : 1;\n    uint8_t unused : 1;\n    uint8_t reserved : 1;\n    uint8_t checksum_flag : 1;\n    uint8_t dict_id_flag : 2;\n}\n```\n\n[^zstd]: [https://github.com/facebook/zstd](https://github.com/facebook/zstd)\n[^zstddoc]: [https://github.com/facebook/zstd/blob/3732a08f5b82ed87a744e65daa2f11f77dabe954/doc/zstd_compression_format.md](https://github.com/facebook/zstd/blob/3732a08f5b82ed87a744e65daa2f11f77dabe954/doc/zstd_compression_format.md)\n\n### ZDictionary\n\nZStandard might use a dictionary[^zdict] to compress the data, and the dictionary is stored either as a separate file, or in the same file as the compressed data. In some cases it might be in the executable itself (very rare!)\nDocumentation on ZDict is sparse, however we know that the magic value is `37 A4 30 EC`\n\nThe ZDict header has the following format:\n\n```c\nstruct zdict_header {\n    uint32_t magic;\n    uint32_t dict_id;\n}\n```\n\n[^zdict]: [https://github.com/facebook/zstd/blob/3732a08f5b82ed87a744e65daa2f11f77dabe954/doc/zstd_compression_format.md#dictionary-format](https://github.com/facebook/zstd/blob/3732a08f5b82ed87a744e65daa2f11f77dabe954/doc/zstd_compression_format.md#dictionary-format)\n\n## Oodle\n\nOodle[^oodle] is a proprietary compression format used in many games, and has a hardware encoder in the PS5.\n\nOodle will always start with `#C` if it is made with version 4 or higher. Version 4 Oodle files have the following format:\n\n```c\nstruct oodle_block_header {\n    uint8_t magic : 4;\n    uint8_t version : 2;\n    bool copy : 1;\n    bool reset : 1;\n    uint8_t compression_type : 7;\n    bool has_checksum : 1;\n}\n```\n\nCompression type will be between 0 and 13 as of Oodle Version 9 (oo2core_9), and the checksum used is a modified Jenkins algorithm.\nFrom this we can deduce that the second byte will be between `00` and `0D`, or `80` and `8D`\n\nNote that Oodle will still load version 3 and older files, which will start with `#0`, `#1`, `#2`, or `#3` and will  usually look like LZW or LZB.\n\n[^oodle]: [http://www.radgametools.com/oodle.htm](http://www.radgametools.com/oodle.htm)\n\n## Tile Streaming (dstorage)\n\nTile Streaming uses a system to decompress multiple blocks simultaneously[^dstorage].\nThe format supports various compression formats, but at the moment only GDeflate[^gdeflate] (a variation of DEFLATE) is recognized.\nThe header is easily tested, the first byte will be the compression type (`04` for GDeflate) followed by that byte XORed with 0xFF (`FB` for GDeflate.) Followed by the number of \"tiles\".\n\nData compressed with GDeflate Tile Streaming will start with `04 FB`.\n\nThis ends up being:\n\n```c\nstruct tile_stream_header {\n    uint8_t compressor_id;\n    uint8_t magic;\n    uint16_t num_tiles;\n    uint32_t tile_size_idx : 2; // this is always 1\n    uint32_t last_tile_size: 18;\n    uint32_t reserved : 12;\n};\n```\n\n[^dstorage]: [https://github.com/microsoft/DirectStorage/tree/56489d25900d916a9cc450f5efe9e62b01789030/GDeflate/GDeflate](https://github.com/microsoft/DirectStorage/tree/56489d25900d916a9cc450f5efe9e62b01789030/GDeflate/GDeflate)\n[^gdeflate]: [https://github.com/NVIDIA/libdeflate](https://github.com/NVIDIA/libdeflate)\n\n## DENSITY\n\nDensity[^density] is a compression algorithm that claims[^density-benchmarks] 2x decompression speed compared to LZ4.\n\nIt has a very predictable header that is easy to spot.\n\n```c\nstruct density_header {\n    uint8_t version_major;\n    uint8_t version_minor;\n    uint8_t version_revision;\n    uint8_t compression_type;\n    uint32_t reserved;\n}\n```\n\nDensity has 18 releases, of which only 3 are not marked as pre released (0.14.0, 0.14.1, 0.14.2). It has 3 compression types (1, 2, 3.)\n\nWe can reduce this to a set byte sequences `00 0E 02 01 00 00 00 00` with 02 being the revision version, and 01 being the compression type.\n\n[^density]: [https://github.com/g1mv/density](https://github.com/g1mv/density)\n[^density-benchmarks]: [https://github.com/g1mv/density?tab=readme-ov-file#benchmarks](https://github.com/g1mv/density?tab=readme-ov-file#benchmarks)\n\n## Zip Signature Speedrun\n\nCompression archives almost always have a signature at the start of the file.\nI'm adding them here for completeness.\n\n- ZIP Magic: `50 4B` (PK)\n- BZip2 Magic: `42 5A 68` (BZh)\n- 7Zip Magic: `37 7A BC AF 27 1C` (7z)\n- Rar Magic: `52 61 72 21 1A 07` (Rar!)\n- WIM Magic: `4D 53 57 49 4D 00 00 00` (MSWIM)\n- Xz Magic: `FD 37 7A 58 5A 00` (7zXZ)\n- Tar Magic: `75 73 74 61 72` (ustar) - usually found at the end of filelist\n\n## Changelog\n\n*Update: 2024-09-09 - Added DENSITY info.*\n\n*Update: 2024-08-19 - Added Tile Streaming info.*\n\n*Update: 2023-07-11 - zenhax is offline, replaced links with archive.org links.*"
    }
  ]
}
